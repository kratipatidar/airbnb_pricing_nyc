## New York City’s Airbnb Price Prediction: An analytic endeavor for predicting NYC Airbnb prices for the year 2019

### Project Background

Airbnb has emerged as an attractive accommodation alternative to the traditional hotels for people involved in leisure as well as necessary travel. Ever since its inception in 2008, increasing number of people have been drawn into the appeal of Airbnb, and have frequently chosen it as their go-to when traveling to a different city, state or another country altogether.
This shift in accommodation preferences does warrant several questions. So, what is it that has led to this change in traditional patterns? Do AirBnBs offer cheaper prices for the same services as offered by a usual hotel/motel/or bed and breakfast? Do AirBnBs offer increased flexibility in terms of booking and cancelation? Do they provide a richer and more personal experience as opposed to the traditional hotel settings? These are just some of the questions that need to be exhaustively researched and analyzed to understand Airbnb’s rise in popularity.
This project aims to predict the price of an Airbnb listing for the year 2019, by building several Machine Learning models that utilize the different attributes provided for a particular listing for price prediction purposes. This price analysis would help to better understand the factors at play that influence the price of a listing, and how does the variation in these factors ultimately affect the price of this particular listing.

### Executive Summary

The motivation behind this project is to analyze the price of all the AirBnB listings in New York City, for the year 2019, in order to draw significant insights into the various parameters affecting the price of these listings, and how this price varies as a function of other factors.
A number of Statistical Learning methods were used in the process of data analysis using R.
This project focuses on the analysis of AirBnB NYC Data for 2019, a publicly available dataset on www.kaggle.com. This project tackles the Regression problem as here, we predict the ‘price’ (dependent variable) of a listing by building regression models using the other independent variables of the dataset.
The analysis process comprised of detailed procedures, to yield sensible regression
results, as the after-effect of various model-fittings.
The very first step of this project was ‘Exploratory Data Analysis’. Plotting graphs for the different variables in the dataset helped to better understand the data distribution and gave a deeper insight into what could be done in terms of data preparation for obtaining better analysis results.

The next step involved data cleaning and preparation. In here, the correct categorization and organization of data were involved along with eliminating predictors that otherwise held the potential to negatively affect the analysis results. Predictors with a high correlation and non-zero variance were eliminated. ‘BoxCox’ transformation helped in making the data distribution normal, which was otherwise quite skewed. This step also involved some feature engineering, wherein I came up with a few new features in an attempt to improve the prediction results. The function for variable importance during the modeling process helped to check whether these new features were informative, or they just added noise to the models.

After the data were deemed fit to proceed with further analyses, informed choices were made in order to narrow down the models to be used for data fitting in the next phase of the project. Models used for training were- Linear Regression, Ridge Regression, Lasso Regression, K-Nearest Neighbors, Principal Components Regression, Principal Least Squares, General Additive Model, Forward Subset Selection, Backward Subset Selection, Random Forest, Decision Tree, Bagging Tree and Boosting Tree.

For all the regression models excluding the trees, the RMSE was fairly high and the R-squared value wasn’t what one expected it to be. However, the regression trees performed fairly better, and yielded a comparatively low value of Root Mean Squared Error (RMSE) and a high value of R- squared. Thus, for my analysis, the decision trees worked better for price prediction as compared to the other regression models.


The value of this analysis is mainly contained in understanding the factors at play that have an effect on the price of a listing. This turns out to be slightly more complex as there are no set parameters that one can refer to, to determine a listing’s price, as is the case for conventional accommodation structures (hotels and motels). A very popular universal parameter to gauge the price and amenities offered by a particular hotel is the star rating. Added to this, a number of hotels have managed to establish their brands over the years. So, it is not tough to understand what to expect out of them. However, since AirBnB is a fairly new concept, it gets quite tricky to understand the prices and amenities associated with a specific listing. There are no star ratings or age-old established brands in this case. But, in today’s scenario, the reviews and star ratings on the internet go a long way in determining a listing’s worth and authenticity. More often than not, people refer to these ratings and reviews in order to make an informed decision for booking-purposes. Added to this, the location of a listing is also a major factor influencing its price. These are just some of the features that this analysis covers to predict a listing’s price to a maximum-achievable level of accuracy.

### Discussion and Conclusion

The final test performance results clearly show that decision trees do a better job at prediction of an AirBnB listing price as compared to other regression models.
However, in my opinion, further processing of the data before modeling could have been done in order to obtain better results for other regression models as well. Eliminating outliers in the dataset and dealing with skewed distributions using better statistical techniques are some of the few measures that I plan to implement on this dataset, which should yield better results. The RMSE values obtained for the different regression models were a bit unsatisfactory. Added to this, low R-squared values indicated that those models didn’t do a very good job at explaining the variation in the response. Decision Trees significantly outdid other regression models in terms of RMSE and R-squared metrics.
Besides this, the number of predictors present in this dataset were quite low. As a result, the scope of feature engineering was severely limited. One way of tackling this issue is to carry out an exhaustive research on market trends prevalent for hotel and AirBnB bookings. The results of such a research can yield other relevant predictors that can help in better predicting the listing prices.
In conclusion, further extensive data processing and including other relevant predictors holds the promise of yielding better prediction results.
